{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1xLba9YzbAfpLttYwxD5v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ignas12345/Magistro_projektas/blob/main/bandymas_klasifikuoti.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "cU_eBl0bbHUu"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "url = 'https://raw.githubusercontent.com/Ignas12345/Magistro_projektas/refs/heads/main/counts_combined.csv'\n",
        "df = pd.read_csv(url)\n",
        "gene_names = df[\"miRNA_ID\"].to_numpy()\n",
        "df_trimmed = df.drop(df.columns[0], axis=1)\n",
        "full_data = (df_trimmed.to_numpy(dtype=np.int32)).T\n",
        "\n",
        "# Create labels: first 6 samples -> label 0, rest -> label 1\n",
        "num_samples = full_data.shape[0]\n",
        "labels = torch.zeros(num_samples, dtype=torch.float32)\n",
        "labels[6:] = 1  # Set the rest of the samples to label 1\n",
        "\n",
        "# Convert full_data to a PyTorch tensor\n",
        "features = torch.tensor(full_data, dtype=torch.float32)\n",
        "\n",
        "mean = features.mean(dim=0)\n",
        "std = features.std(dim=0)\n",
        "features = (features - mean) / (std + 1e-8)\n",
        "\n",
        "# Combine features and labels into a dataset\n",
        "dataset = TensorDataset(features, labels)\n",
        "\n",
        "# Create a DataLoader for batching\n",
        "batch_size = 1  # You can adjust this as needed\n",
        "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Example: Print the shape of a batch\n",
        "for batch_features, batch_labels in data_loader:\n",
        "    print(f\"Batch features shape: {batch_features.shape}\")\n",
        "    print(f\"Batch labels shape: {batch_labels.shape}\")\n",
        "    break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e0tFFYAcnle",
        "outputId": "1cfb3444-f93d-48a2-9a35-609dd4fbb6b9"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch features shape: torch.Size([1, 1881])\n",
            "Batch labels shape: torch.Size([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch_features, batch_labels in data_loader:\n",
        "    print(f\"Batch features shape: {batch_features}\")\n",
        "    print(f\"Batch labels shape: {batch_labels}\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7MFlevNmseU",
        "outputId": "04a174e1-3f54-4243-ed80-9ef24868b4de"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch features shape: tensor([[ 47204.,  46983.,  47453.,  ...,    408.,   2981., 137966.]])\n",
            "Batch labels shape: tensor([1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class SparseNN(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(SparseNN, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "\n",
        "        self.first_layer_weights = nn.Parameter(torch.randn(input_dim))  # 1D tensor for scaling\n",
        "        self.first_layer_biases = nn.Parameter(torch.randn(input_dim))  # 1D tensor for bias\n",
        "\n",
        "\n",
        "        # Second layer: Sparse weighting (learnable parameters)\n",
        "        self.output_weights_raw = nn.Parameter(torch.randn(input_dim))  # Raw weights\n",
        "\n",
        "    def forward(self, x):\n",
        "        # First layer: Linear transformation\n",
        "        first_layer_output = x * self.first_layer_weights + self.first_layer_biases\n",
        "\n",
        "        # Second layer: Apply sparse weights\n",
        "        output_weights = torch.relu(self.output_weights_raw)  # Enforce non-negativity\n",
        "        weighted_output = first_layer_output * output_weights  # Element-wise multiplication\n",
        "  # Element-wise multiplication\n",
        "\n",
        "        # Pooling: Sum the weighted outputs\n",
        "        pooled_output = weighted_output.sum(dim=1)  # Summing across features\n",
        "\n",
        "        # Final activation: tanh\n",
        "        output = torch.sigmoid(pooled_output)\n",
        "        return output\n",
        "\n"
      ],
      "metadata": {
        "id": "eM5yeyfSWIqo"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#initialize the model\n",
        "input_dim = full_data.shape[1]\n",
        "model = SparseNN(input_dim)\n",
        "\n",
        "# Define a loss function and optimizer\n",
        "criterion = nn.BCELoss()  # Binary Cross Entropy Loss for binary classification\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # L1 sparsity via weight_decay"
      ],
      "metadata": {
        "id": "dWKjCuxSlA19"
      },
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "u0gHb8mXTh7C",
        "outputId": "0fff081f-9fd0-466a-802b-09189c7ba7d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 2.8778\n",
            "Epoch [2/10], Loss: 2.8777\n",
            "Epoch [3/10], Loss: 2.8777\n",
            "Epoch [4/10], Loss: 2.8777\n",
            "Epoch [5/10], Loss: 2.8777\n",
            "Epoch [6/10], Loss: 2.8777\n",
            "Epoch [7/10], Loss: 2.8777\n",
            "Epoch [8/10], Loss: 2.8777\n",
            "Epoch [9/10], Loss: 2.8777\n",
            "Epoch [10/10], Loss: 2.8777\n",
            "Final Accuracy: 0.9712\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# L1 Regularization (sparsity enforcement)\n",
        "def l1_regularization(weight, lambda_l1=0.001):\n",
        "    return lambda_l1 * weight.abs().sum()\n",
        "\n",
        "# Training Loop\n",
        "num_epochs = 10  # Adjust based on dataset size and convergence\n",
        "lambda_l1 = 0.001  # Regularization strength\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for batch_features, batch_labels in data_loader:\n",
        "        # Forward pass\n",
        "        outputs = model(batch_features)  # Ensure shape compatibility for BCELoss\n",
        "        # Compute binary cross-entropy loss\n",
        "        loss = criterion(outputs, batch_labels)\n",
        "\n",
        "        # Add L1 regularization for sparsity\n",
        "        #loss += l1_regularization(model.output_weights_raw, lambda_l1)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Logging epoch statistics\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {total_loss / len(data_loader):.4f}\")\n",
        "\n",
        "# Evaluation (after training)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    # Forward pass on the entire dataset\n",
        "    predictions = model(features).squeeze()\n",
        "    predictions = (predictions > 0.5).float()  # Convert probabilities to binary predictions\n",
        "\n",
        "    # Compute accuracy\n",
        "    accuracy = accuracy_score(labels.numpy(), predictions.numpy())\n",
        "    print(f\"Final Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(features[0:2])\n",
        "print(model(features).squeeze())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxXeME3tiw6N",
        "outputId": "e9cefc6b-9c48-4dec-8a43-1e6cff59197f"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2.0663, 2.0594, 2.0604,  ..., 2.2183, 0.9937, 1.1071],\n",
            "        [5.3856, 5.3786, 5.4246,  ..., 5.9588, 4.3934, 2.3196]])\n",
            "tensor([1.0000, 0.0020, 1.0000, 1.0000, 1.0000, 0.0019, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        0.9989, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9991, 1.0000,\n",
            "        1.0000, 0.9944, 1.0000, 1.0000], grad_fn=<SqueezeBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the weights of the first layer\n",
        "print(\"First Layer Weights:\")\n",
        "print(torch.Tensor.size(model.first_layer_weights.data))\n",
        "\n",
        "# Print the biases of the first layer (if present)\n",
        "print(\"First Layer Biases:\")\n",
        "print(model.first_layer_biases.data)\n",
        "\n",
        "# Print the weights of the second layer (output weights)\n",
        "print(\"Second Layer (Sparse) Weights:\")\n",
        "print(torch.relu(model.output_weights_raw.data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTqC-PIcXGej",
        "outputId": "2fbb1e59-aa9e-4563-e6d0-96e18569bdef"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Layer Weights:\n",
            "torch.Size([1881])\n",
            "First Layer Biases:\n",
            "tensor([-0.8275, -1.5632, -0.5364,  ..., -1.3576, -0.1697, -0.6520])\n",
            "Second Layer (Sparse) Weights:\n",
            "tensor([0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.5769e+00, 0.0000e+00,\n",
            "        1.7388e-04])\n"
          ]
        }
      ]
    }
  ]
}